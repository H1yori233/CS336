{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44af0ab1",
   "metadata": {},
   "source": [
    "# CS336 Assignment 3 (scaling): Scaling Laws"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c032d7a1",
   "metadata": {},
   "source": [
    "### 2 Scaling Laws Review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11864793",
   "metadata": {},
   "source": [
    "### Problem (chinchilla_isoflops): 5 points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16957a8",
   "metadata": {},
   "source": [
    "Write a script to reproduce the IsoFLOPs method describe above for fitting scaling laws using the final training loss from a set of training runs. For this problem, use the (synthetic) data from training runs given in the file `data/isoflops_curves.json`. This file contains a JSON array, where each element is an object describing a training run. Here are the first two runs for illustrating the format:\n",
    "\n",
    "```json\n",
    "[\n",
    "  {\n",
    "    \"parameters\": 49999999,\n",
    "    \"compute_budget\": 6e+18,\n",
    "    \"final_loss\": 7.192784500319437\n",
    "  },\n",
    "  {\n",
    "    \"parameters\": 78730505,\n",
    "    \"compute_budget\": 6e+18,\n",
    "    \"final_loss\": 6.750171320661809\n",
    "  },\n",
    "  ...\n",
    "]\n",
    "```\n",
    "\n",
    "For fitting the scaling laws, the `scipy` package (and `scipy.optimize.curve_fit` in particular) might be useful, but you’re welcome to use any curve fitting method you’d like. While Hoffmann et al. [2022] fits a quadratic function to each IsoFLOP profile to find its minimum, we instead recommend you simply take the run with the lowest training loss for each compute budget as the minimum.\n",
    "\n",
    "1.  Show your extrapolated compute-optimal model size, together with the $\\langle C\\_i, N\\_{opt}(C\\_i) \\rangle$ points you obtained. What is your predicted optimal model size for a budget of $10^{23}$ FLOPs? What about for $10^{24}$ FLOPs?\n",
    "\n",
    "**Deliverable**: A plot showing your scaling law for model size by compute budget, showing the data points used to fit the scaling law and extrapolating up to at least $10^{24}$ FLOPs. Then, a one-sentence response with your predicted optimal model size.\n",
    "\n",
    "-----\n",
    "\n",
    "<span style=\"background-color: #29B6F6; color: black\">\n",
    "a\n",
    "</span>\n",
    "\n",
    "-----\n",
    "\n",
    "2.  Show your extrapolated compute-optimal dataset size, together with the $\\langle C\\_i, D\\_{opt}(C\\_i) \\rangle$ data points from the training runs. What is your predicted optimal dataset size for budgets of $10^{23}$ and $10^{24}$ FLOPs?\n",
    "\n",
    "**Deliverable**: A plot showing your scaling law for dataset size by compute budget, showing the data points used to fit the scaling law and extrapolating up to at least $10^{24}$ FLOPs. Then, a one-sentence response with your predicted optimal dataset size.\n",
    "\n",
    "-----\n",
    "\n",
    "<span style=\"background-color: #29B6F6; color: black\">\n",
    "a\n",
    "</span>\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ebdea5",
   "metadata": {},
   "source": [
    "### 3 Constructing Scaling Laws"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc8697d",
   "metadata": {},
   "source": [
    "### Problem (scaling_laws): 50 points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11afabee",
   "metadata": {},
   "source": [
    "Construct a scaling law to accurately predict the optimal model size, its hyperparameters, and the associated training loss for a FLOPs budget of $10^{19}$. To construct your scaling laws, you will use our training API to query the final training loss for various experimental configurations ($\\S 3.1$); you may not query more than $2 \\cdot 10^{18}$ FLOPs worth of experiments for fitting your scaling law. This is hard cap that will be enforced by the API.\n",
    "\n",
    "Note on batch size: We place essentially no constraints on the hyperparameters you may report under the FLOPs budget of $10^{19}$, other than the following requirement: your batch size must be either 128 or 256. This is done to ensure that runs have reasonably high model FLOPs utilization. If we have issues with out-of-memory errors when running your reported hyperparameter configuration, we will either use gradient accumulation or scale the number of data parallel GPUs to maintain your desired batch size.\n",
    "\n",
    "To help you get started, we recommend thinking about at least the following questions. Your writeup should contain additional commentary about how decisions were made for each factor below:\n",
    "\n",
    "  * Given your fixed scaling laws budget of $2 \\cdot 10^{18}$, how did you decide which runs to query?\n",
    "  * How did you fit your scaling law? Describe the concrete method or methods you used. In particular, it will likely to be useful to familiarize yourself with the approaches used in Kaplan et al. [2020] and Hoffmann et al. [2022].\n",
    "  * How well does your scaling law fit the experimental data?\n",
    "  * For our given FLOPs budget of $10^{19}$, what optimal model size does your scaling law predict? What is the predicted loss?\n",
    "  * If you were to train a model with your predicted optimal number of parameters, what hyperparameters would you use? To estimate the number of non-embedding parameters for a given model hyperparameter configuration, use $12 \\cdot n\\_{layer} \\cdot d^2\\_{model}$.\n",
    "\n",
    "\n",
    "**Deliverable**: A typeset write-up that contains a complete description of your approach and methodology for fitting a scaling law. In addition, it should describe how you use the scaling law to predict the optimal model size for the given FLOPs budget, and your predicted values. The write-up should include commentary about why you made particular design decisions, and the description should be detailed enough to reproduce your approach and results. In addition to the report, submit your (1) predicted optimal model size, (2) the training hyperparameters to use including either batch size 128 or 256, and (3) the model’s training loss to this Google form: [https://forms.gle/sAUSLwCUETew2hYN6](https://forms.gle/sAUSLwCUETew2hYN6). Part of your grade on the assignment will be determined by the performance of your predicted optimal model.\n",
    "\n",
    "-----\n",
    "\n",
    "<span style=\"background-color: #29B6F6; color: black\">\n",
    "a\n",
    "</span>\n",
    "\n",
    "-----"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
